{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":11076055,"datasetId":6894310,"databundleVersionId":11464344}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Notebook: Feature Engineering - desc - 1\n# Author: Thomas Purk\n# Date: 2025-03-17\n# Reference: https://www.kaggle.com/datasets/mchirico/montcoalert","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:07:12.324246Z","iopub.execute_input":"2025-03-18T13:07:12.324521Z","iopub.status.idle":"2025-03-18T13:07:13.130530Z","shell.execute_reply.started":"2025-03-18T13:07:12.324496Z","shell.execute_reply":"2025-03-18T13:07:13.129273Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/emergency-911-calls-mcpa/911.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## desc - Data Exploration","metadata":{}},{"cell_type":"code","source":"# Notebook Step up steps\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndf_in_path = '/kaggle/input/emergency-911-calls-mcpa/911.csv'\ndf_out_path = '/kaggle/working/911.csv'\n\n# Load the data \ndf_911 = pd.read_csv(df_in_path)\n\ndef report_null_empty(df, feature):\n    ''' Prints the count and percent of total of null or empty feature (column) values.\n    \n    Parameters: \n        df (dataframe): A Pandas dataframe which contains the fature.\n        feature (string): The name of the feature in the dataframe to report on.\n    '''\n    null_count = df[feature].isnull().sum()\n    empty_count = (df[feature] == \"\").sum()\n    false_count = (df[feature] == False).sum()\n    nan_count = (df[feature].isna()).sum()\n    print('')\n    print(f'{feature}: Null / Empty Report')\n    print(f'\\tRow count: {len(df)}')\n    print(f'\\tNull count: {null_count}')\n    print(f'\\tNull percent: {round(null_count / len(df) * 100,6)}%')\n    print(f'\\tEmpty count: {empty_count}')\n    print(f'\\tEmpty precent: {round(empty_count / len(df) * 100,6)}%')\n    print(f'\\tFalse count: {false_count}')\n    print(f'\\tFalse precent: {round(false_count / len(df) * 100,6)}%')\n    print(f'\\tNAN count: {nan_count}')\n    print(f'\\tNAN precent: {round(nan_count / len(df) * 100,6)}%')\n\ndef get_one_offs(df, feature):\n\n    # Count occurrences of each value in feature\n    value_counts = df[feature].value_counts()\n    \n    # Identify values that appear only once\n    unique_values = value_counts[value_counts == 1].index\n    \n    # Filter the DataFrame to include only rows with unique values in feature\n    return df[df[feature].isin(unique_values)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:08:39.862711Z","iopub.execute_input":"2025-03-18T13:08:39.863033Z","iopub.status.idle":"2025-03-18T13:08:43.569852Z","shell.execute_reply.started":"2025-03-18T13:08:39.863008Z","shell.execute_reply":"2025-03-18T13:08:43.568938Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Display basic information\ndisplay(df_911.info())\ndisplay(df_911.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:09:09.022110Z","iopub.execute_input":"2025-03-18T13:09:09.022549Z","iopub.status.idle":"2025-03-18T13:09:09.242754Z","shell.execute_reply.started":"2025-03-18T13:09:09.022519Z","shell.execute_reply":"2025-03-18T13:09:09.241674Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 649696 entries, 0 to 649695\nData columns (total 8 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   desc       649696 non-null  object \n 1   zip        574587 non-null  float64\n 2   title      649696 non-null  object \n 3   timeStamp  649696 non-null  object \n 4   twp        649696 non-null  object \n 5   addr       649696 non-null  object \n 6   e          649696 non-null  int64  \n 7   twp_type   649696 non-null  object \ndtypes: float64(1), int64(1), object(6)\nmemory usage: 39.7+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                                                desc      zip  \\\n0  REINDEER CT & DEAD END;  NEW HANOVER; Station ...  19525.0   \n1  BRIAR PATH & WHITEMARSH LN;  HATFIELD TOWNSHIP...  19446.0   \n2  HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...  19401.0   \n3  AIRY ST & SWEDE ST;  NORRISTOWN; Station 308A;...  19401.0   \n4  CHERRYWOOD CT & DEAD END;  LOWER POTTSGROVE; S...      NaN   \n\n                     title            timeStamp                        twp  \\\n0   EMS: BACK PAINS/INJURY  2015-12-10 17:10:52       NEW HANOVER TOWNSHIP   \n1  EMS: DIABETIC EMERGENCY  2015-12-10 17:29:21          HATFIELD TOWNSHIP   \n2      Fire: GAS-ODOR/LEAK  2015-12-10 14:39:21         NORRISTOWN BOROUGH   \n3   EMS: CARDIAC EMERGENCY  2015-12-10 16:47:36         NORRISTOWN BOROUGH   \n4           EMS: DIZZINESS  2015-12-10 16:56:52  LOWER POTTSGROVE TOWNSHIP   \n\n                         addr  e  twp_type  \n0      REINDEER CT & DEAD END  1  township  \n1  BRIAR PATH & WHITEMARSH LN  1  township  \n2                    HAWS AVE  1   borough  \n3          AIRY ST & SWEDE ST  1   borough  \n4    CHERRYWOOD CT & DEAD END  1  township  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>desc</th>\n      <th>zip</th>\n      <th>title</th>\n      <th>timeStamp</th>\n      <th>twp</th>\n      <th>addr</th>\n      <th>e</th>\n      <th>twp_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>REINDEER CT &amp; DEAD END;  NEW HANOVER; Station ...</td>\n      <td>19525.0</td>\n      <td>EMS: BACK PAINS/INJURY</td>\n      <td>2015-12-10 17:10:52</td>\n      <td>NEW HANOVER TOWNSHIP</td>\n      <td>REINDEER CT &amp; DEAD END</td>\n      <td>1</td>\n      <td>township</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BRIAR PATH &amp; WHITEMARSH LN;  HATFIELD TOWNSHIP...</td>\n      <td>19446.0</td>\n      <td>EMS: DIABETIC EMERGENCY</td>\n      <td>2015-12-10 17:29:21</td>\n      <td>HATFIELD TOWNSHIP</td>\n      <td>BRIAR PATH &amp; WHITEMARSH LN</td>\n      <td>1</td>\n      <td>township</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>\n      <td>19401.0</td>\n      <td>Fire: GAS-ODOR/LEAK</td>\n      <td>2015-12-10 14:39:21</td>\n      <td>NORRISTOWN BOROUGH</td>\n      <td>HAWS AVE</td>\n      <td>1</td>\n      <td>borough</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AIRY ST &amp; SWEDE ST;  NORRISTOWN; Station 308A;...</td>\n      <td>19401.0</td>\n      <td>EMS: CARDIAC EMERGENCY</td>\n      <td>2015-12-10 16:47:36</td>\n      <td>NORRISTOWN BOROUGH</td>\n      <td>AIRY ST &amp; SWEDE ST</td>\n      <td>1</td>\n      <td>borough</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHERRYWOOD CT &amp; DEAD END;  LOWER POTTSGROVE; S...</td>\n      <td>NaN</td>\n      <td>EMS: DIZZINESS</td>\n      <td>2015-12-10 16:56:52</td>\n      <td>LOWER POTTSGROVE TOWNSHIP</td>\n      <td>CHERRYWOOD CT &amp; DEAD END</td>\n      <td>1</td>\n      <td>township</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Inspect the desc feature\nprint(\"### desc ###\")\ndisplay(df_911['desc'].describe())\nreport_null_empty(df_911,'desc')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:09:18.043007Z","iopub.execute_input":"2025-03-18T13:09:18.043467Z","iopub.status.idle":"2025-03-18T13:09:19.026611Z","shell.execute_reply.started":"2025-03-18T13:09:18.043430Z","shell.execute_reply":"2025-03-18T13:09:19.025494Z"}},"outputs":[{"name":"stdout","text":"### desc ###\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"count                                                649696\nunique                                               649457\ntop       CITY AVE & CARDINAL AVE;  LOWER MERION; Statio...\nfreq                                                      5\nName: desc, dtype: object"},"metadata":{}},{"name":"stdout","text":"\ndesc: Null / Empty Report\n\tRow count: 649696\n\tNull count: 0\n\tNull percent: 0.0%\n\tEmpty count: 0\n\tEmpty precent: 0.0%\n\tFalse count: 0\n\tFalse precent: 0.0%\n\tNAN count: 0\n\tNAN precent: 0.0%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# NOTE: desc column values have no nulls and are highly unique\n# NOTE: desc column values seem to contain multiple features delimited by \";\"\n# NOTE: could be a station feature embedded in the desc.\n\n# Inspect split of desc feature\ndesc_split = df_911['desc'].str.split(';', expand=True)\ndisplay(desc_split.info())\ndisplay(desc_split.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T13:09:27.078271Z","iopub.execute_input":"2025-03-18T13:09:27.078684Z","iopub.status.idle":"2025-03-18T13:09:29.158031Z","shell.execute_reply.started":"2025-03-18T13:09:27.078657Z","shell.execute_reply":"2025-03-18T13:09:29.157196Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 649696 entries, 0 to 649695\nData columns (total 5 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   0       649696 non-null  object\n 1   1       649696 non-null  object\n 2   2       649696 non-null  object\n 3   3       649696 non-null  object\n 4   4       325044 non-null  object\ndtypes: object(5)\nmemory usage: 24.8+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                            0                    1  \\\n0      REINDEER CT & DEAD END          NEW HANOVER   \n1  BRIAR PATH & WHITEMARSH LN    HATFIELD TOWNSHIP   \n2                    HAWS AVE           NORRISTOWN   \n3          AIRY ST & SWEDE ST           NORRISTOWN   \n4    CHERRYWOOD CT & DEAD END     LOWER POTTSGROVE   \n\n                                      2                       3     4  \n0                           Station 332   2015-12-10 @ 17:10:52        \n1                           Station 345   2015-12-10 @ 17:29:21        \n2   2015-12-10 @ 14:39:21-Station:STA27                          None  \n3                          Station 308A   2015-12-10 @ 16:47:36        \n4                           Station 329   2015-12-10 @ 16:56:52        ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>REINDEER CT &amp; DEAD END</td>\n      <td>NEW HANOVER</td>\n      <td>Station 332</td>\n      <td>2015-12-10 @ 17:10:52</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BRIAR PATH &amp; WHITEMARSH LN</td>\n      <td>HATFIELD TOWNSHIP</td>\n      <td>Station 345</td>\n      <td>2015-12-10 @ 17:29:21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAWS AVE</td>\n      <td>NORRISTOWN</td>\n      <td>2015-12-10 @ 14:39:21-Station:STA27</td>\n      <td></td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AIRY ST &amp; SWEDE ST</td>\n      <td>NORRISTOWN</td>\n      <td>Station 308A</td>\n      <td>2015-12-10 @ 16:47:36</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHERRYWOOD CT &amp; DEAD END</td>\n      <td>LOWER POTTSGROVE</td>\n      <td>Station 329</td>\n      <td>2015-12-10 @ 16:56:52</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Accumulated Notes\n- desc column values have no nulls and are highly unique\n- desc column values seem to contain multiple features delimited by \";\"\n- but \";\" is not a reliable delimiter\n- could be a station feature embedded in the desc.\n\n\n**Actions**\n- engineer a new 'station' feature by extracting unique text from 'desc'","metadata":{}},{"cell_type":"code","source":"''' Engineer new feature \"station\"\n    The goal is to find valuable data in the desc field if any\n    \n    - Clean up \"desc\" to create a new \"station\" feature\n    - Remove substrings that are repeated in other fields\n    - \";\" is not a reliable delimiter\n'''\n\n# Loop through rows using iterrows()\nfor index, row in df_911.iterrows():\n\n    # Create a variable containing the string to clean up\n    new_value = row['desc']\n\n    # Create a list of clean values to inspect\n    # The Desc feature contains timestamps Example: \"2015-12-10 @ 17:10:52\"\n    # But the timeStamp feature is formated as  \"2015-12-10 17:10:52\"\n    # So split the timeStamp by ' @ ' and remove each part seperately\n    new_value = new_value.replace(' @ ',' ')\n    \n    ## The Desc feature contains timestamps Example: \"2015-12-10 @ 17:10:52\"\n    ## But the timeStamp feature is formated as  \"2015-12-10 17:10:52\"\n    ## So split the timeStamp by ' ' and remove each part seperately\n    ts_parts = row['timeStamp'].split(' ')\n    new_value = new_value.replace(ts_parts[0], '')\n    new_value = new_value.replace(ts_parts[1], '')\n\n    \n    # Remove addr string\n    # Have some bad addr values that are just integers, can't use them because they\n    if(not row['addr'].isdigit()):\n        new_value = new_value.replace(row['addr'], '')\n\n\n    # Remove twp string\n    # Must account for the normilization of the twp feature that took place previously\n    twp = str(row['twp']).replace(' TOWNSHIP','').replace(' BOROUGH','')\n    new_value = new_value.replace(twp, '')\n    \n    # # 1. Raw String\n    # new_value = new_value.replace(str(row['twp']), '')\n    # # 2. Raw String - ' TOWNSHIP'\n    # new_value = new_value.replace(str(row['twp']).replace(' TOWNSHIP',''), '')\n    # # 3. Raw String - ' BORO'\n    # new_value = new_value.replace(str(row['twp']).replace(' BOROUGH',' BORO'), '')\n    # # 4. Raw String - ' BOROUGH'\n    # new_value = new_value.replace(str(row['twp']).replace(' BOROUGH',''), '')\n  \n    # clean up delimiters\n    new_value = new_value.replace(';','')\n    new_value = new_value.replace('@','')\n    new_value = new_value.replace('-','')\n    new_value = new_value.replace(':','')\n\n    # \"Station\" and \"STA\" are not needed\n    new_value = new_value.replace('Station','')\n    new_value = new_value.replace('STA','')\n\n    # Must account for the normilization of the twp feature that took place previously\n    # so, will need to try 4 version of the string\n    new_value = new_value.replace('TOWNSHIP', '').replace('BORO', '').replace('BOROUGH', '')\n\n    # Final white space cleanup\n    new_value = new_value.strip()\n    \n    # Write the remaining string as a new feature\n    df_911.at[index, 'station'] = new_value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:26:35.718776Z","iopub.execute_input":"2025-03-18T14:26:35.719093Z","iopub.status.idle":"2025-03-18T14:27:32.070672Z","shell.execute_reply.started":"2025-03-18T14:26:35.719071Z","shell.execute_reply":"2025-03-18T14:27:32.069667Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Inspect the desc feature\nprint(\"### station ###\")\ndisplay(df_911['station'].describe())\nreport_null_empty(df_911,'station')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:28:11.313938Z","iopub.execute_input":"2025-03-18T14:28:11.314335Z","iopub.status.idle":"2025-03-18T14:28:11.646372Z","shell.execute_reply.started":"2025-03-18T14:28:11.314305Z","shell.execute_reply":"2025-03-18T14:28:11.645385Z"}},"outputs":[{"name":"stdout","text":"### station ###\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"count     649696\nunique       158\ntop             \nfreq      225660\nName: station, dtype: object"},"metadata":{}},{"name":"stdout","text":"\nstation: Null / Empty Report\n\tRow count: 649696\n\tNull count: 0\n\tNull percent: 0.0%\n\tEmpty count: 225660\n\tEmpty precent: 34.733168%\n\tFalse count: 0\n\tFalse precent: 0.0%\n\tNAN count: 0\n\tNAN precent: 0.0%\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# 'EMS' & 'FIRE' are too generic for station ids, how many are there\ndf_911[df_911['station'].isin(['FIRE','EMS'])]['station'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:32:16.258080Z","iopub.execute_input":"2025-03-18T14:32:16.258610Z","iopub.status.idle":"2025-03-18T14:32:16.305999Z","shell.execute_reply.started":"2025-03-18T14:32:16.258572Z","shell.execute_reply":"2025-03-18T14:32:16.304901Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"station\nEMS     176\nFIRE      6\nName: count, dtype: int64"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"# Set EMS and FIRE to ''\ndf_911.loc[df_911['station'].isin(['FIRE','EMS']),'station'] = ''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:32:18.702783Z","iopub.execute_input":"2025-03-18T14:32:18.703100Z","iopub.status.idle":"2025-03-18T14:32:18.741284Z","shell.execute_reply.started":"2025-03-18T14:32:18.703074Z","shell.execute_reply":"2025-03-18T14:32:18.740208Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# Look at stations with only one occurance\nstation_one_offs = get_one_offs(df_911, 'station')\nprint(f'Station One Off Count: {len(station_one_offs)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:33:20.038008Z","iopub.execute_input":"2025-03-18T14:33:20.038471Z","iopub.status.idle":"2025-03-18T14:33:20.158444Z","shell.execute_reply.started":"2025-03-18T14:33:20.038433Z","shell.execute_reply":"2025-03-18T14:33:20.157461Z"}},"outputs":[{"name":"stdout","text":"Station One Off Count: 21\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"# List unique stations\nprint(df_911['station'].value_counts().to_string())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:32:27.337693Z","iopub.execute_input":"2025-03-18T14:32:27.338008Z","iopub.status.idle":"2025-03-18T14:32:27.402400Z","shell.execute_reply.started":"2025-03-18T14:32:27.337983Z","shell.execute_reply":"2025-03-18T14:32:27.401401Z"}},"outputs":[{"name":"stdout","text":"station\n                          225842\n308A                       25321\n329                        21879\n313                        20309\n381                        15937\n345                        14468\n308                        13947\n351                        12695\n345B                       12156\n317                        11752\n382                        11160\n322A                       10614\n308B                        9126\n339                         8032\n344                         7766\n318                         7761\n384                         7717\n358                         7608\n352                         7431\n358A                        6704\n385                         6429\n324                         6404\n322                         6170\n345A                        6072\n369                         5935\n325                         5457\n313A                        5391\n27                          5256\n332                         5235\n355                         5194\n383                         5177\n336                         5028\n324A                        4768\n69                          4718\n311                         4023\n356                         3889\n329B                        3849\n351A                        3647\n308C                        3605\n47                          2745\n10                          2676\n344A                        2459\n88                          2430\n15                          2332\n33                          2238\n18                          2229\n29                          2079\n7                           2023\n53                          2022\n23                          1963\n54                          1910\n25                          1892\n28                          1882\n200                         1871\n61                          1803\n14                          1759\n100                         1741\n8                           1681\n500                         1658\n44                          1631\n99                          1562\n1                           1538\n98                          1412\n89                          1385\n46                          1362\n22                          1360\n26                          1344\n76                          1343\n352A                        1193\n74                          1190\n17                          1147\n24                          1117\n6                           1086\n43                          1084\n80                          1050\n58                          1047\n3                           1034\n36                          1021\n86                          1012\n48                          1008\n83                           985\n37                           972\n96                           954\n82                           887\n4                            885\n95                           883\n3A85                         854\n21                           852\n62                           831\n67                           798\n65                           795\n77                           794\n35                           778\n51                           766\n300                          758\n2                            742\n45                           738\n34                           725\n38                           685\n79                           681\n66                           663\n56                           648\n75                           617\n5                            601\n57                           599\n39                           574\n331                          515\n12                           514\n59                           513\n356A                         500\n42                           463\n78                           455\n72                           453\n49                           448\n400                          429\n71                           407\n87                           391\n700                          390\n7A505                        386\n31                           386\n52                           383\n11                           288\n9                            246\n32                           183\n73                           159\n4A151                        147\n4A114                         66\n6A15                          59\n4A108                         14\n3A84                           9\n3A2                            7\nHANOVER ST MT ZION AVE         2\nRT 100 HOFFERCKER RD           2\n202                            2\n724                            2\nENHAM                          1\nLOWER MORE                     1\n8931    311                    1\n341                            1\n711    351                     1\n512                            1\n422                            1\n1736                           1\n81                             1\nFRANIA                         1\n2185                           1\n801                            1\n84                             1\n1330                           1\n309                            1\n228                            1\nNORRIS                         1\n600                            1\nER SALFORD                     1\n429                            1\n56FD                           1\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"## Additional Notes\n- Station has a high percentage of missing values\n- But low instance of one-off values could means that it is a decent categorical value\n- Based on additional research here https://wiki.radioreference.com/index.php/Montgomery_County_(PA)\n- Many of the station ids appear valid.\n- Station id's seem to be tied to a dispatch region\n- However, station ids may repeat among EMS, Fire, HazMAt, and several type of law enforcement.\n- So while it might be possible to validate and match the station id to the correct department via the \"title\" column\n- ... and it might be possble to fill in the 34% missing values via imputation based on the addr column\n- ... the quality of the data would be questionable and it is not clear how station would benefit a model analysis\n- ... over the addr column\n- Decision is to remove both the desc and station columns.","metadata":{}},{"cell_type":"code","source":"# drop the desc column\ndf_911.drop('desc', axis=1, inplace=True)\n\n# drop the station column\ndf_911.drop('station', axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:42:52.437928Z","iopub.execute_input":"2025-03-18T14:42:52.438317Z","iopub.status.idle":"2025-03-18T14:42:52.548086Z","shell.execute_reply.started":"2025-03-18T14:42:52.438287Z","shell.execute_reply":"2025-03-18T14:42:52.547037Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# Update the file\n# After Updating\n# 1. Manually Download locally\n# 2. Manually Updload to a new version of the Kaggle Dataset\n\n\n# Check if file exists\nif os.path.exists(df_out_path):\n    os.remove(df_out_path)\n    print(f\"File '{df_out_path}' has been deleted.\")\nelse:\n    print(f\"The file '{df_out_path}' does not exist.\")\n\ndf_911.to_csv(df_out_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T14:43:06.553432Z","iopub.execute_input":"2025-03-18T14:43:06.553799Z","iopub.status.idle":"2025-03-18T14:43:09.326954Z","shell.execute_reply.started":"2025-03-18T14:43:06.553767Z","shell.execute_reply":"2025-03-18T14:43:09.325828Z"}},"outputs":[{"name":"stdout","text":"The file '/kaggle/working/911.csv' does not exist.\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}